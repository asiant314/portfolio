[
	{
		"question": "You are new to a project and there's no persona or customer segmentation information available. How would you go about developing personas that are representative and practical as design tools?",
		"answer": "Applies a mixed methods approach, involves both ethnographic work in addition to surveys, market segment data, usage logs, Understands difference between market segments and personas. Discusses approaches for dissemination, usage of persona",
		"tag": ["tag1", "tag2"]
	},
	{
		"question": "Your eng team is paralyzed as they have so many features they want to build for the next quarter, but only enough resources to do a couple. Design a study to help them prioritize what they should work on, to drive the most conversion.",
		"answer": "Talks through different feature prioritization approaches (Kano, conjoint, max diff, ratings). Includes initial formative/foundation research to identify user needs.",
		"tag": ["tag3", "tag4"]
	},
	{
		"question": "You are evaluating 3 different UI text options for an app download screen. You can test these options via a series of moderated usability session or via an online survey tool. How do you determine which approach you pick? For the survey based approach, how many people do you end up surveying? Would you show them each of the 3 variants? Only one?",
		"answer": "Tradeoffs in study design, usability to iteratively improve, identify issues in variants at the cost of time and resources. Surveys to scale for larger audiences, quantitative comparisons across the designs. Survey sampling and study design (within vs between subject tradeoffs).",
		"tag": ["tag3", "tag4"]
	},
	{
		"question": "In usability studies, how would you describe your moderation style? What is your best technique to capture behaviors and reactions most representative of how users will do in the real world setting? Participants don't talk? Participants that talk non-stop? Participants who think they know what you want to hear?",
		"answer": "Focus on behavior, less so on subjective statements. Moderation best practices for moving studies along at a good pace while gathering high quality data. Making sure participants are comfortable, building up rapport.",
		"tag": ["tag3", "tag4"]
	},
	{
		"question": "After launching new designs for a product, your long-time users had a strong negative reaction to the initial designs. Design a research plan to study and understand the reaction. You are particularly concerned with separating out change aversion from core problems.",
		"answer": "Focuses on tracking sentiment and change aversion. Recognizes that there is some time before stabilization. Baseline before and after comparisons with satisfaction tracking. Looks at only new users to control for change bias",
		"tag": ["tag3", "tag4"]
	},

	{
		"question": "Suppose you are joining a relatively young team yet to have the luxury of having a dedicated user researcher. What are some strategies you would employ to help the team better leverage your core competencies?",
		"answer": "Focus on building rapport with team, defining processes, building relationships. Encouraging participation in design activities, research. UXR 101 type of seminar. Regular brown bags to demonstrate impact of research",
		"tag": ["tag3", "tag4"]
	},
	{
		"question": "Talk through your typical process and timeline for conducting a more tactical usability study? How would this change if you were given half the time to complete the research?",
		"answer": "Explores lightweight usability approaches (cafe studies, remote usability, unmoderated usability, internal studies, advisory boards). Recognizes potential tradeoffs with these approaches",
		"tag": ["tag3", "tag4"]
	},
	{
		"question": "How would you evaluate a concept for a new product or service that has not yet been seen in the market, in other words there is no direct peer or competitor to compare it.",
		"answer": "Ethnographic research to understand user needs, inform concepts. Competitive review to understand what is currently out there, though caveat being you don’t want to become too fixated on existing designs such that it impedes innovation (ex/ in focus groups, I’ve seen occasions where users often reference other products and features that they found exciting). Concept study to explore early ideas. Trade-off between concept studies and survey based approaches such as Kano/MaxDiff. Concept studies are great at diving deep, though it’s time consuming (creating concepts) and you are often limited in how many you can share. You can use a storyboard to describe the concept holistically within a flow. Surveys allow for greater scale (number of concepts, number of participants and subsegments of users), since these responses are quantified, you can get more nuanced comparisons and rankings of concepts",
		"tag": ["tag3", "tag4"]
	},
	{
		"question": "What have you found to be the most effective ways to communicate your research findings and recommendations? Provide examples.",
		"answer": "Range of approaches depending on audience. Domains international research across 5 countries. Crafted two different presentations depending on audience. First one was to the entire xfnal team (eng, business, leadership, ux). This was a broad audience, and my goal here was to increase awareness and empathy about he international adoption of our product. Decided to do first send out a broader quiz to the team, with questions based on our research findings. Then during the presentation, I showed the results of the survey responses along with the correct answer. This was a great way to demonstrate how the team’s initial conceptions may or may not have aligned with our actual research findings. Added a bonus android figurine for the the top quiz scorers as a bit of motivation also. Second approach was a smaller group of 5-6 stakeholders (PMs, business leads, eng leads). Goal here was different, instead intent was to drive action based on the findings. I reiterated some of the high-level points from the research but I left this presentation more open-ended allowing for discussion and brainstorm of ideas.",
		"tag": ["tag3", "tag4"]
	},
	{
		"question": "Whether or not the idea was eventually adopted, describe a situation in which one of your research efforts resulted in you having an interesting or novel product or feature idea. ",
		"answer": "I was conducting a shop-along type of exploratory exercise to understand how users select domain names for their business. The goal of this research was to generate ideas for iteration of our search process within Domains. I provided users with a re-imbursement, watched them work through the process of finding a domain name. One area that stood out in this walk through was the emphasis users placed on social media handles. For them, a business wasn’t just the website name but also an instagram, twitter identity, business listings on Facebook, Yelp. The underlying need for users was to have a cohesive brand for their digital presence. The idea that came out of this was… could we also check social media availability in addition to domain names as part of the search experience?",
		"tag": ["tag3", "tag4"]
	},

	{
		"question": "Describe a difficult situation you encountered with a product team (e.g. strong opinions and personalities).  How did you deal with this situation?",
		"answer": "On the AWS marketing team, there tended to be some tension between the marketing analytics team (responsible for A/B testing) and the UX team. I received a number of questions about the generalizability of my insights from qualitative work, mostly along the lines of… we haven’t really seen this as an issue in our log data. Underlying this is a question about small sample sized qualitative research. Early in my career I would take a more defensive approach towards it and go into thesis defense mode, talking through the rigor of the research approach. I’ve shifted away from that  and instead start by trying to understand where the log data is coming from. I reframe it as another dimension that can be used to tell a cohesive story. Often, I find that it’s not really in conflict with the qualitative insights and when you dig deeper into the log data, complemented with the qualitative you get a more thorough understanding. I also talk through how the questions being answered by these data sources are different. Logs -> more about how often and what is happening, while qual -> why it’s occurring, the intent behind actions. As an example, let's say you introduced a CTA and the engagement rate is incredibly low… is it an issue of discovery or utility? ",
		"tag": ["tag3", "tag4"]
	},

	{
		"question": "Describe a situation in which your research plan or insights were challenged by stakeholders. How did you deal with this situation?",
		"answer": "Worked really hard on a feature redesign within Google Domains, informed by iterative usability studies, and grounded by early foundational work. As part of the post-launch process, we conducted A/B testing and there were some serious considerations to take into account. Both an influx of negative feedback and a reduction in A/B metrics. Some of this I’ve experienced before in other products and I pointed out how often with redesigns there may be an initial negative reaction. Some of the open-ended feedback related to aesthetics, and though helpful to note should also be balanced by change aversion. One approach I proposed to tease out some of this impact is to actually give the metrics some more time. I also suggested breaking the metrics down into new users vs old users to help control for change resistance (there new users would not be impacted by the old design).",
		"tag": ["tag3", "tag4"]
	},

	{
		"question": "Tell me about a time you had to deliver negative feedback to a team member.",
		"answer": "I was mentoring a researcher on my team and had given him the lead on a research project. During the course of the project, there were a few instances where I didn’t think he communicated effectively to the stakeholders. In the first, the researcher did not loop in stakeholders regularly and so they were surprised when a study announcement was sent out a few days before the first participant was scheduled. This left the stakeholders off-guard and felt unprepared for the research. This led to a delay of the research and a rescheduling of the participants. In the second instance, I noticed that the stakeholders (design/pm) came out of a research meeting somewhat frustrated. In leading the meeting, the researcher was deferring to design/pm to often make research decisions (how many concepts should we test, how should we word these concepts). I followed up with design/pm to verify that the observations were correct before talking with the researcher one-on-one. I framed the feedback in terms of action and impact versus focusing on the researcher themselves. For example, “I noticed that in the meeting stakeholders were often asked about research design decisions. It’s great to include stakeholders in this planning process but leaving it that open-ended places a lot of burden on the stakeholders to also be researchers. Oftentimes they are turning to you as the expert. An alternative approach could be to provide a stronger point of view on what you would recommend given your expertise and if the stakeholders disagree or have alternative opinions, this would then be a great point of discussion.",
		"tag": ["tag3", "tag4"]
	},

	{
		"question": "What are the weaknesses of personas? How do you overcome those weaknesses?",
		"answer": "How are they to be used? Can we get alignment on high priority persona? Personas are a great resource when it comes to providing a frame of reference for designers, developers, product managers. They can all reference back to the persona when trying to frame key decision points. In addition, it creates a realism and sense of empathy when you can refer back by name to the persona, place that persona within a scenario, and walk through how they may perceive of a feature. What goes into creating a persona can often lead to limitations in use. For example, I’ve seen instances where personas are mainly market segments, consisting of demographic profile information. There is no backstory that drives the needs of the persona. On the other hand, I’ve seen personas made with dubious supporting evidence. Despite the story telling nature of crafting personas, these are based on a certain level of evidence. You use a mixture of focus groups, interviews, contextual inquiries, observational studies, market segmentation data to build up an understanding of the user groups. From this you can craft the personas for distinct groups. I’ve found that you get the most out of creating the personas since this involves a fair amount of research and data gathering. As you transition that into the persona story, unfortunately some of the information will get lost. A third party reading the persona, though it may be helpful, loses out on the context driven by persona creation. I’ve found in this case that having designers involved with the persona creation process pays dividends. ",
		"tag": ["tag3", "tag4"]
	}


]